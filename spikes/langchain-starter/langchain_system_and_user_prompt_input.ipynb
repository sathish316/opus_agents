{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e5948-1070-4a7c-9724-47eef3ccbcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup API keys\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAIA_API_KEY\"] = getpass.getpass(\"Enter OpenAI API key:\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider = \"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e504b8-535a-491e-bd1a-c57b0c810260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call LLM with SystemMessage and HumanMessage\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English to Italian\"),\n",
    "    HumanMessage(\"Let's drink Spritz\")\n",
    "]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436f8c0-442c-45e2-a5a7-b5b7c9824880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User message\n",
    "model.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540abf4a-8dd2-4de8-80b7-78674b8e72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to pass User message\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260637ca-7c96-4214-b978-4ca52f3e50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to pass User message\n",
    "model.invoke([HumanMessage(\"hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f339d95-96ec-4728-b413-4f5bf2584cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model with system message and human message for a task\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English to Italian, Spanish, French, German\"),\n",
    "    HumanMessage(\"The quick brown fox jumped over the lazy dog\")\n",
    "]\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095e0c3-c398-4856-9f20-3dcf9544774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model with system message and pass input using ChatPromptTemplate and String interpolation\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English to {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": \"italian\", \"text\": \"the quick brown fox\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35822ec7-a550-4bf7-b797-f9236bfb21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416498c4-b137-4c84-ae4d-45841509693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4feb746-13bc-4b70-a607-ee2cfaf76c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
